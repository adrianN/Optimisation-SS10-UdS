The lecture is comprised of three parts

\begin{itemize}
\item Linear Programming
\item Integer Linear Programming
\item Approximation Algorithms
\end{itemize}

\section{Introduction and Examples}
\begin{itemize}
\item Approximation Algorithms
\begin{Ex} Suppose we have $n$ jobs $\nthings{w}\in \R^+$ and two machines and want to minimize the total running time of the jobs. This problem is NP-complete (reduction e.g. Knapsack). A heuristic could be assigning jobs always to the machine with the lower load.

How does a schedule such computed compare to the optimal? Every sensible algorithm is at least within a factor of two of the optimal schedule. Since we only have two machines we can't do more than two units of work concurrently. The heuristic is however a $3/2$ approximation.

The proof is easy: Let $w_{max}$ be the size of the maximal job. No schedule can be faster than $w_{max}$. Hence $\mbox{opt} \geq \max (w_{max}, w/2)$. Consider the situation before the last job is assigned. The size of the assigned jobs is $W-w_n$ so the less leoded machine (wlog 2) has a load at most $(W-w_n)/2$. Assuming machine 2 determines the total length, the algorithm produces a schedule of length 

\[\frac{(W-w_n)}{2} + w_n \leq W/2+w_n/2 \leq \mbox{opt} + \mbox{opt}/2\]
\end{Ex}
\item Linear and Integer Linear Programming. We have a number of variables $\nthings{x}\in \R$ subject to linear constraints $1\leq j\leq m$
\[a_{j1}x_1 + \ldots + a_{jn} x_n \leq b_j \qquad a_{ij},b_i \in \R\]

\begin{Ex}[The diet problem.] We have $x_i$ of food $i$. Different foods have different features, e.g. calories, price. You can write down different constraints, for example the amount of fat. The example objective function could be price. If the packaging is discrete we need an integer solution. There are of course instances which require mixed integer/real answers.
\end{Ex}

There are a large number of problems that can be formulated using LPs. There are efficient solution for normal LPs, ILPs however are NP-complete (but still can be solved comparatively efficient). There is also a large body of knowledege about linear programs. Lastly LPs and ILPs are a good basis for developing approximation algorithms, for example by dropping integrality constraints and rounding cleverly.

\begin{Ex}[Max-Flow as LP] We want to maximise the flow through a network from source to sink. A flow has to satisfy the capacity and the flow conservation constraints. Those constraints can be formulated as a LP.
\begin{align*}
\forall e\qquad & 0\leq f(e)\leq cap(e)\\
\forall v\in V\backslash \{s,t\}\qquad & \sum_{e=(u,v)} f(e) = \sum_{e=(v,u)} f(e)\\
\intertext{The coal is to maximise the flow out of s:}
 &\sum_{e=(s,v)} f(e)
\end{align*}
\end{Ex}

\begin{Ex}[Min (s,t)-cut problem] The Min-Cut problem is similar to the Max-Flow problem. We want to remove a set of edges with minimal weight s.t. no path from $s$ to $t$ remains. Let $y_e=1$ mean $e$ is in the cut: the $y_i$ are integral and either 0 or 1.
\[\forall \mbox{paths}\ p: \sum_{e\in p} y_e \geq 1\]
The objective is to minimize 

\[\sum_e cap(e)\cdot y_e\]

The value of the mit-cut and max-flow problems are always the same and the LPs are duals of each other. Also the integrality constraints are unnecessary. Some kinds of LPs always have a integral optimal solution (besides potential fractional solutions).
\end{Ex}

\begin{Ex}[Satisfiability] We're given a boolean formula in CNF and want to check if it is satisfiable. Let $\nthings x$ be booleon variables and $\nthings y$ and $\nthings z$ were $y_i=1$ iff $x_i$ and $z_i=1$ iff $C_i$.

We simplify by asking how many clauses can be satisfied:

\[\max \sum z_i\]

To relate clauses with their variables define $C_j^+$ to be the positive variables in $C_j$, $C_j^-$ analogous. Then we can write 

\[\sum_{x_j\in C_j^+} \sum x_j + \sum_{x_i \in C_j^-} (1-x_i) \geq z_j\]

With these constraints $z_j$ can only be 1 if at least one of the positive variables is 1 or one of the negatives is 0.

If we drop the integrality constraints we can derive an approximation algorithm by introducing probabilistic rounding. This is a very good algorithm (as we'll see later in the course).
\end{Ex}
\end{itemize}